{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb0de297",
   "metadata": {},
   "source": [
    "# Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840cd0f1",
   "metadata": {},
   "source": [
    "## Process raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd2c6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train XDF Files: 20\n",
      "Number of Test XDF Files: 36\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Initialize lists\n",
    "train_sess_lst = []\n",
    "test_sess_lst = []\n",
    "train_xdf_lst = []\n",
    "test_xdf_lst = []\n",
    "\n",
    "# Define the base data directory\n",
    "data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "# Define the total number of sessions\n",
    "N = 3\n",
    "\n",
    "# Loop through each subject directory\n",
    "for item in os.listdir(data_dir):\n",
    "    subject_path = os.path.join(data_dir, item)\n",
    "    if os.path.isdir(subject_path):\n",
    "        # Loop through session numbers\n",
    "        for i in range(1, N + 1):\n",
    "            session_path = os.path.join(subject_path, f\"ses-S00{i}\", \"eeg\")\n",
    "            if os.path.isdir(session_path):\n",
    "                # Add .xdf files to the respective lists\n",
    "                xdf_files = [f for f in os.listdir(session_path) if f.endswith('.xdf')]\n",
    "                for xdf_file in xdf_files:\n",
    "                    full_xdf_path = os.path.join(session_path, xdf_file)\n",
    "                    if i == 1:\n",
    "                        train_xdf_lst.append(full_xdf_path)\n",
    "                    else:\n",
    "                        test_xdf_lst.append(full_xdf_path)\n",
    "\n",
    "# Print results\n",
    "print(\"Number of Train XDF Files:\", len(train_xdf_lst))\n",
    "print(\"Number of Test XDF Files:\", len(test_xdf_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cbd59ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading P{file_name} ...\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "511.9686313424893\n",
      "Creating RawArray with float64 data, n_channels=33, n_times=95997\n",
      "    Range : 0 ... 95996 =      0.000 ...   187.492 secs\n",
      "Ready.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "6 from event_id is not present in events.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 89\u001b[0m\n\u001b[1;32m     80\u001b[0m event_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial start - NoGo\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial start - Go\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m7\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeedback\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m158\u001b[39m,\n\u001b[1;32m     87\u001b[0m }\n\u001b[1;32m     88\u001b[0m color_dict \u001b[38;5;241m=\u001b[39m {event: color \u001b[38;5;28;01mfor\u001b[39;00m event, color \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(unique_events, plt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mviridis(np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(unique_events))))}\n\u001b[0;32m---> 89\u001b[0m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_events\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Create epochs for event_id 14\u001b[39;00m\n\u001b[1;32m     92\u001b[0m event_id \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m14\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m14\u001b[39m}\n",
      "File \u001b[0;32m<decorator-gen-107>:12\u001b[0m, in \u001b[0;36mplot_events\u001b[0;34m(events, sfreq, first_samp, color, event_id, axes, equal_spacing, show, on_missing, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/bci/lib/python3.9/site-packages/mne/viz/misc.py:827\u001b[0m, in \u001b[0;36mplot_events\u001b[0;34m(events, sfreq, first_samp, color, event_id, axes, equal_spacing, show, on_missing, verbose)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m this_event \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m unique_events:\n\u001b[1;32m    826\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthis_event\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from event_id is not present in events.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 827\u001b[0m         \u001b[43m_on_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_missing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    828\u001b[0m         keep[ii] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    829\u001b[0m conditions \u001b[38;5;241m=\u001b[39m [cond \u001b[38;5;28;01mfor\u001b[39;00m cond, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(conditions, keep) \u001b[38;5;28;01mif\u001b[39;00m k]\n",
      "File \u001b[0;32m~/miniforge3/envs/bci/lib/python3.9/site-packages/mne/utils/check.py:1191\u001b[0m, in \u001b[0;36m_on_missing\u001b[0;34m(on_missing, msg, name, error_klass)\u001b[0m\n\u001b[1;32m   1189\u001b[0m on_missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarning\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m on_missing\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_klass(msg)\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m on_missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1193\u001b[0m     warn(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: 6 from event_id is not present in events."
     ]
    }
   ],
   "source": [
    "# Effective stream must be greater than 1Hz \n",
    "import mne\n",
    "import numpy as np\n",
    "import pyxdf\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function to get stream indices based on type\n",
    "def get_stream_indices(streams, type_data, type_trig):\n",
    "    i_data, i_trig = -1, -1\n",
    "    for i, stream in enumerate(streams):\n",
    "        stream_type = stream['info']['type'][0].lower()\n",
    "        effective_srate = float(stream['info']['effective_srate'])\n",
    "        print(effective_srate)\n",
    "        if type_data in stream_type:\n",
    "            i_data = i\n",
    "        # if type_trig in stream_type and effective_srate > 0: ## use for sub-yy1\n",
    "        if type_trig in stream_type: # use for all other subjects\n",
    "            i_trig = i\n",
    "    return i_data, i_trig\n",
    "\n",
    "# Load XDF files iteratively from the folder py\n",
    "folder_name = \"/Users/jhpark/Desktop/VR-BCI-Cognitive-Training/data/sub-jh1/ses-S002/eeg\"\n",
    "# folder_name = \"/home/minsu/Dropbox/Projects/VRCogTraining/Data/sub-yy1/ses-S001/eeg\"\n",
    "\n",
    "files = [f for f in os.listdir(folder_name) if f.endswith(\".xdf\")]\n",
    "\n",
    "all_go_epochs = []\n",
    "all_nogo_epochs = []\n",
    "\n",
    "for file in files:\n",
    "    file_name = os.path.join(folder_name, file)\n",
    "    print(\"loading P{file_name} ...\")\n",
    "    streams, header = pyxdf.load_xdf(file_name)\n",
    "\n",
    "    # Automatically determine the indices for each file\n",
    "    i_data, i_trig = get_stream_indices(streams, 'eeg', 'stim') # i_data - 1, i_trig - 0\n",
    "\n",
    "    # Extract EEG data\n",
    "    data = np.array(streams[i_data][\"time_series\"]).T\n",
    "    sfreq = float(streams[i_data][\"info\"][\"nominal_srate\"][0])\n",
    "    n_chan = 32\n",
    "    data_times = np.array(streams[i_data][\"time_stamps\"])\n",
    "\n",
    "    # Convert to volts (if data is in microvolts)\n",
    "    data /= 1e6\n",
    "\n",
    "    # Extract trigger data\n",
    "    trig = np.array(streams[i_trig][\"time_series\"]).astype(int)\n",
    "    trig_times = np.array(streams[i_trig][\"time_stamps\"])\n",
    "\n",
    "    # Interpolate trigger data to match the EEG data sampling rate\n",
    "    interp_func = interp1d(trig_times, trig.flatten(), kind='nearest', fill_value=\"extrapolate\")\n",
    "    trigger_resampled = interp_func(np.arange(len(data[0])) / sfreq + data_times[0])\n",
    "\n",
    "    # Append the trigger channel to the EEG data\n",
    "    data_with_trigger = np.vstack((data[0:n_chan, :], trigger_resampled))\n",
    "\n",
    "    # Create channel names variable\n",
    "    channel_names = [ch['label'][0] for ch in streams[i_data]['info']['desc'][0]['channels'][0]['channel'] if ch['type'][0] == 'EEG'] + ['TRIGGER']\n",
    "\n",
    "    # Create MNE info and RawArray for EEG data with trigger channel\n",
    "    info = mne.create_info(\n",
    "        ch_names=channel_names,\n",
    "        sfreq=sfreq,\n",
    "        ch_types=['eeg'] * n_chan + ['stim']\n",
    "    )\n",
    "    raw_data = mne.io.RawArray(data_with_trigger, info)\n",
    "\n",
    "    # Manually create events array from trigger channel\n",
    "    trig_diff = np.diff(trigger_resampled)\n",
    "    events_indices = np.where(trig_diff != 0)[0] + 1\n",
    "    events = np.column_stack((events_indices, np.zeros(len(events_indices)), trigger_resampled[events_indices].astype(int)))\n",
    "    events = events.astype(int)\n",
    "\n",
    "    # Print and plot events\n",
    "    unique_events = np.unique(events[:, 2])\n",
    "    event_colors = dict(zip(unique_events, plt.cm.viridis(np.linspace(0, 1, len(unique_events)))))\n",
    "    event_dict = {\n",
    "        \"Trial start - NoGo\": 6,\n",
    "        \"Trial start - Go\": 7,\n",
    "        \"Stimulus 1\": 14,\n",
    "        \"Stimulus 2\": 30,\n",
    "        \"Subject response\": 62,\n",
    "        \"Feedback\": 158,\n",
    "    }\n",
    "    color_dict = {event: color for event, color in zip(unique_events, plt.cm.viridis(np.linspace(0, 1, len(unique_events))))}\n",
    "    mne.viz.plot_events(events, sfreq=sfreq, color=color_dict, event_id=event_dict)\n",
    "\n",
    "    # Create epochs for event_id 14\n",
    "    event_id = {'14': 14}\n",
    "    epochs = mne.Epochs(raw_data, events, event_id=event_id, tmin=-1.0, tmax=4.0, baseline=(None, 0), detrend=1, picks=['CZ'], preload=True)\n",
    "\n",
    "    # Identify trials where event 14 follows a 7 (Go) or 6 (NoGo)\n",
    "    go_trials = [i for i in range(len(events) - 1) if events[i, 2] == 7 and events[i + 1, 2] == 14]\n",
    "    nogo_trials = [i for i in range(len(events) - 1) if events[i, 2] == 6 and events[i + 1, 2] == 14]\n",
    "\n",
    "    # Convert to indices relative to epochs and ensure 1-based indexing\n",
    "    go_trials = [epochs.selection.tolist().index(i + 1) for i in go_trials if i + 1 in epochs.selection]\n",
    "    nogo_trials = [epochs.selection.tolist().index(i + 1) for i in nogo_trials if i + 1 in epochs.selection]\n",
    "\n",
    "    # Select epochs for Go and NoGo\n",
    "    go_epochs = epochs[go_trials]\n",
    "    nogo_epochs = epochs[nogo_trials]\n",
    "\n",
    "    # Append to all epochs list\n",
    "    all_go_epochs.append(go_epochs)\n",
    "    all_nogo_epochs.append(nogo_epochs)\n",
    "\n",
    "# Concatenate all epochs\n",
    "all_go_epochs = mne.concatenate_epochs(all_go_epochs)\n",
    "all_nogo_epochs = mne.concatenate_epochs(all_nogo_epochs)\n",
    "\n",
    "# Average the concatenated epochs\n",
    "go_evoked = all_go_epochs.average()\n",
    "nogo_evoked = all_nogo_epochs.average()\n",
    "\n",
    "# Plot Go ERP\n",
    "fig_go = go_evoked.plot(picks=['CZ'])\n",
    "fig_go.suptitle('ERP for Event ID 14 Followed by Go', fontsize=16)\n",
    "\n",
    "# Plot NoGo ERP\n",
    "fig_nogo = nogo_evoked.plot(picks=['CZ'])\n",
    "fig_nogo.suptitle('ERP for Event ID 14 Followed by NoGo', fontsize=16)\n",
    "\n",
    "# Show plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3603ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
