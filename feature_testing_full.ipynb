{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Note I altered tmin to 2.3, tmax to 4.3, and baseline to (None, 3) before running this notebook '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Note I altered tmin to 2.3, tmax to 4.3, and baseline to (None, 3) before running this notebook \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import extract_eeg, preprocess, prepare_data, run_model, evaluate_model, compute_empirical_chance\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'lda'                       # classifier ('svm', 'rf', 'lda', 'xgb')\n",
    "PCA, N_COMPONENTS = True, 20        # PCA downsampling\n",
    "TIME_DOWNSAMPLE_FACTOR = 4          # Time downsampling factor\n",
    "N_FOLDS = 4                         # num. folds for K_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "channel = 'Cz'\n",
    "window_size = 50  # Num samples in moving average window\n",
    "\n",
    "def moving_average(signal, window_size):\n",
    "    return np.convolve(signal, np.ones(window_size) / window_size, mode='valid')\n",
    "\n",
    "def compute_grand_average_with_error(epochs, channel, window_size):\n",
    "    data = epochs.get_data(picks=channel)  # Shape: (n_epochs, n_times)\n",
    "    smoothed_signals = []\n",
    "\n",
    "    for epoch_signal in data:  # Each epoch_signal is a 1D array (n_times,)\n",
    "        smoothed_signal = moving_average(epoch_signal.flatten(), window_size)\n",
    "        smoothed_signals.append(smoothed_signal)\n",
    "    \n",
    "    smoothed_signals = np.array(smoothed_signals)  # Shape: (n_epochs, n_times after smoothing)\n",
    "    grand_averaged_signal = np.mean(smoothed_signals, axis=0)\n",
    "    standard_error = np.std(smoothed_signals, axis=0) / np.sqrt(smoothed_signals.shape[0])  # SEM\n",
    "    return grand_averaged_signal, standard_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACT EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded_data\\train_A.fif already exists. Loading data.\n",
      "Reading c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\loaded_data\\train_A.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    5000.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:52: RuntimeWarning: This filename (loaded_data\\train_A.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs = mne.read_epochs(fif_name, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "240 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "File loaded_data\\test_A_s2.fif already exists. Loading data.\n",
      "Reading c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\loaded_data\\test_A_s2.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    5000.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:52: RuntimeWarning: This filename (loaded_data\\test_A_s2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs = mne.read_epochs(fif_name, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "216 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "File loaded_data\\test_A_s3.fif already exists. Loading data.\n",
      "Reading c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\loaded_data\\test_A_s3.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    5000.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:52: RuntimeWarning: This filename (loaded_data\\test_A_s3.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs = mne.read_epochs(fif_name, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "216 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "# Data Split A\n",
    "train_pth_A = Path(r\"data/train_A\")                    # ses1 \n",
    "test_pth_A_s2 = Path(r\"data/test_A_ses2\")              # ses2\n",
    "test_pth_A_s3 = Path(r\"data/test_A_ses3\")              # ses3\n",
    "\n",
    "# train data load (use .fif if exists else create new)\n",
    "all_go_epochs_train_A, all_nogo_epochs_train_A = extract_eeg(folder_name=train_pth_A, fif_name=Path(r\"loaded_data/train_A.fif\"))\n",
    "all_go_epochs_test_A_s2, all_nogo_epochs_test_A_s2 = extract_eeg(folder_name=test_pth_A_s2, fif_name=Path(r\"loaded_data/test_A_s2.fif\"))\n",
    "all_go_epochs_test_A_s3, all_nogo_epochs_test_A_s3 = extract_eeg(folder_name=test_pth_A_s3, fif_name=Path(r\"loaded_data/test_A_s3.fif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 0.01 - 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 1.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.00 Hz)\n",
      "- Filter length: 168961 samples (330.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:238: RuntimeWarning: filter_length (168961) is longer than the signal (3073), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  all_go_epochs.filter(l_freq=0.01, h_freq=1.0)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=1)]: Done 2177 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=1)]: Done 3041 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=1)]: Done 3527 tasks      | elapsed:   52.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 0.01 - 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 1.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.00 Hz)\n",
      "- Filter length: 168961 samples (330.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:239: RuntimeWarning: filter_length (168961) is longer than the signal (3073), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  all_nogo_epochs.filter(l_freq=0.01, h_freq=1.0)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=1)]: Done 2177 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=1)]: Done 3041 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=1)]: Done 3527 tasks      | elapsed:   51.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "EEG channel type selected for re-referencing\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Setting up band-pass filter from 0.01 - 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 1.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.00 Hz)\n",
      "- Filter length: 168961 samples (330.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:242: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  all_go_epochs.set_eeg_reference('average', projection=True)  # 'average' means CAR\n",
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:243: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  all_nogo_epochs.set_eeg_reference('average', projection=True)\n",
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:238: RuntimeWarning: filter_length (168961) is longer than the signal (3073), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  all_go_epochs.filter(l_freq=0.01, h_freq=1.0)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=1)]: Done 2177 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=1)]: Done 3041 tasks      | elapsed:   42.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 0.01 - 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 1.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.00 Hz)\n",
      "- Filter length: 168961 samples (330.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:239: RuntimeWarning: filter_length (168961) is longer than the signal (3073), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  all_nogo_epochs.filter(l_freq=0.01, h_freq=1.0)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=1)]: Done 2177 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=1)]: Done 3041 tasks      | elapsed:   47.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "EEG channel type selected for re-referencing\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Setting up band-pass filter from 0.01 - 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 1.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.00 Hz)\n",
      "- Filter length: 168961 samples (330.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:242: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  all_go_epochs.set_eeg_reference('average', projection=True)  # 'average' means CAR\n",
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:243: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  all_nogo_epochs.set_eeg_reference('average', projection=True)\n",
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:238: RuntimeWarning: filter_length (168961) is longer than the signal (3073), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  all_go_epochs.filter(l_freq=0.01, h_freq=1.0)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=1)]: Done 2177 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=1)]: Done 3041 tasks      | elapsed:   45.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 0.01 - 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 1.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.00 Hz)\n",
      "- Filter length: 168961 samples (330.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:239: RuntimeWarning: filter_length (168961) is longer than the signal (3073), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  all_nogo_epochs.filter(l_freq=0.01, h_freq=1.0)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=1)]: Done 2177 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=1)]: Done 3041 tasks      | elapsed:   39.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "EEG channel type selected for re-referencing\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Projections have already been applied. Setting proj attribute to True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:242: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  all_go_epochs.set_eeg_reference('average', projection=True)  # 'average' means CAR\n",
      "c:\\Users\\ranit\\Neural_Projects\\VR-BCI-Cognitive-Training\\helpers.py:243: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  all_nogo_epochs.set_eeg_reference('average', projection=True)\n"
     ]
    }
   ],
   "source": [
    "all_go_epochs_train_A, all_nogo_epochs_train_A = preprocess(all_go_epochs_train_A, all_nogo_epochs_train_A)\n",
    "all_go_epochs_test_A_s2, all_nogo_epochs_test_A_s2 = preprocess(all_go_epochs_test_A_s2, all_nogo_epochs_test_A_s2)\n",
    "all_go_epochs_test_A_s3, all_nogo_epochs_test_A_s3 = preprocess(all_go_epochs_test_A_s3, all_nogo_epochs_test_A_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPARE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A_rn, y_train_A_rn, X_test_A_s2_rn, y_test_A_s2_rn = prepare_data(all_go_epochs_train_A_rn, all_nogo_epochs_train_A_rn, all_go_epochs_test_A_s2_rn, all_nogo_epochs_test_A_s2_rn, \n",
    "                                                                            time_ds_factor=TIME_DOWNSAMPLE_FACTOR, use_pca=PCA, n_components=N_COMPONENTS)\n",
    "_, _, X_test_A_s3_rn, y_test_A_s3_rn = prepare_data(all_go_epochs_train_A_rn, all_nogo_epochs_train_A_rn, all_go_epochs_test_A_s3_rn, all_nogo_epochs_test_A_s3_rn, \n",
    "                                                        time_ds_factor=TIME_DOWNSAMPLE_FACTOR, use_pca=PCA, n_components=N_COMPONENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_rn, avg_accuracy_A_rn, classification_reports_A_rn, confusion_matrices_A_rn = run_model(X_train_A_rn, y_train_A_rn, mdl=MODEL, n_splits=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results for Training on S1\")\n",
    "print(f\"RN Fold Train Accuracy: {avg_accuracy_A_rn * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nResults for Test on S2\")\n",
    "y_pred_A_s2_rn = model_A_rn.predict(X_test_A_s2_rn)\n",
    "metrics_A_s2_rn = evaluate_model(y_test_A_s2_rn, y_pred_A_s2_rn)\n",
    "print(f\"RN Test Accuracy: {metrics_A_s2_rn['accuracy'] * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nResults for Test on S3\")\n",
    "y_pred_A_s3_rn = model_A_rn.predict(X_test_A_s3_rn)\n",
    "metrics_A_s3_rn = evaluate_model(y_test_A_s3_rn, y_pred_A_s3_rn)\n",
    "print(f\"RN Test Accuracy: {metrics_A_s3_rn['accuracy'] * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
